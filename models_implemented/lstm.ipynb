{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RNN (LSTM) Model for Human Action Recognition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. INITIALIZATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1.1. IMPORT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "matplotlib          3.4.3\n",
       "numpy               1.21.3\n",
       "pandas              1.3.4\n",
       "session_info        1.0.0\n",
       "sklearn             1.0.1\n",
       "torch               1.10.0+cu102\n",
       "torchvision         0.11.1+cu102\n",
       "tqdm                4.62.3\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                         8.4.0\n",
       "astunparse                  1.6.3\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "cffi                        1.15.0\n",
       "colorama                    0.4.4\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.4.3\n",
       "decorator                   5.1.0\n",
       "defusedxml                  0.7.1\n",
       "entrypoints                 0.3\n",
       "google                      NA\n",
       "ipykernel                   6.4.1\n",
       "ipython_genutils            0.2.0\n",
       "jedi                        0.18.0\n",
       "joblib                      1.1.0\n",
       "kiwisolver                  1.3.2\n",
       "matplotlib_inline           NA\n",
       "mpl_toolkits                NA\n",
       "nbinom_ufunc                NA\n",
       "nt                          NA\n",
       "ntsecuritycon               NA\n",
       "parso                       0.8.2\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "prompt_toolkit              3.0.20\n",
       "psutil                      5.8.0\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.4.1\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pyexpat                     NA\n",
       "pygments                    2.10.0\n",
       "pyparsing                   3.0.6\n",
       "pythoncom                   NA\n",
       "pytz                        2021.3\n",
       "pywin32_bootstrap           NA\n",
       "pywin32_system32            NA\n",
       "pywintypes                  NA\n",
       "scipy                       1.7.2\n",
       "six                         1.16.0\n",
       "storemagic                  NA\n",
       "threadpoolctl               3.0.0\n",
       "tornado                     6.1\n",
       "traitlets                   5.1.0\n",
       "typing_extensions           NA\n",
       "wcwidth                     0.2.5\n",
       "win32api                    NA\n",
       "win32com                    NA\n",
       "win32security               NA\n",
       "zmq                         22.3.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             7.29.0\n",
       "jupyter_client      7.0.2\n",
       "jupyter_core        4.7.1\n",
       "notebook            6.4.3\n",
       "-----\n",
       "Python 3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]\n",
       "Windows-10-10.0.22000-SP0\n",
       "-----\n",
       "Session information updated at 2022-01-18 15:31\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fill the requirement.txt file we use the following line of code:\n",
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1.2. DATA LOADING*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/nturgbd_skeletons_cleaned/\"\n",
    "data_files = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/actions.txt\", 'r') as actions_file:\n",
    "    actions = [line.replace('\\n', '') for line in actions_file.readlines()]\n",
    "    actions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 : pickup\n",
      "class 1 : throw\n",
      "class 2 : sitting down\n",
      "class 3 : standing up (from sitting position)\n",
      "class 4 : take off jacket\n",
      "class 5 : reach into pocket\n",
      "class 6 : pointing to something with finger\n",
      "class 7 : check time (from watch)\n",
      "class 8 : falling\n"
     ]
    }
   ],
   "source": [
    "classes = [5, 6, 7, 8, 14, 24, 30, 32, 42]\n",
    "for i,elem in enumerate(classes):\n",
    "    print(\"class {} : {}\".format(i, actions[elem]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanActionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, data_files, classes):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_files = []\n",
    "        for data_file in data_files:\n",
    "            if int(data_file[17:-4])-1 in classes:\n",
    "                self.data_files = self.data_files + [data_file]\n",
    "        self.classes = classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor = torch.Tensor(np.load(self.data_dir + self.data_files[idx]))\n",
    "        tensor = tensor.reshape((tensor.shape[0], 75))\n",
    "        label = int(self.data_files[idx][17:-4])-1\n",
    "        label = self.classes.index(label)\n",
    "        return (tensor, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also build a dataset in which we are going to mask some joints to see if our model is robust enough to missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanActionDataset_Masked(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, data_files, classes, percentage):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_files = []\n",
    "        self.percentage = percentage\n",
    "        for data_file in data_files:\n",
    "            if int(data_file[17:-4])-1 in classes:\n",
    "                self.data_files = self.data_files + [data_file]\n",
    "        self.classes = classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor = torch.Tensor(np.load(self.data_dir + self.data_files[idx]))\n",
    "        tensor = tensor.reshape((tensor.shape[0], 75))\n",
    "        label = int(self.data_files[idx][17:-4])-1\n",
    "        label = self.classes.index(label)\n",
    "        joints_to_hide = rd.sample(range(25), int(25*self.percentage))\n",
    "        for joint_to_hide in joints_to_hide:\n",
    "            for i in range(tensor.shape[0]):\n",
    "                tensor[i][joint_to_hide*3:joint_to_hide*3+3] = -10 # all values are above -3 normally\n",
    "        return (tensor, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to use PyTorchâ€™s DataLoader with Variable Length Sequences for LSTM/GRU : from this [article](https://www.codefull.net/2018/11/use-pytorchs-dataloader-with-variable-length-sequences-for-lstm-gru/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadSequence():\n",
    "\n",
    "    def __call__(self, batch):\n",
    "\n",
    "        # let's assume that each element in \"batch\" is a tuple (data, label).\n",
    "        # the following line of code sort the batch in the descending order\n",
    "        sorted_batch = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
    "        \n",
    "        # then we take each sequence of the batch and pad it\n",
    "        sequences = [x[0] for x in sorted_batch]\n",
    "        sequences_padded_end = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
    "\n",
    "        lengths = torch.LongTensor([len(x) for x in sequences])\n",
    "\n",
    "        # here we adjust the padding because we want zeros at the beginning\n",
    "        # (we had poor results with zeros at the end)\n",
    "        sequences_padded_begin = torch.stack(\n",
    "            [torch.cat([\n",
    "                sequences_padded_end[i][lengths[i]:],\n",
    "                sequences_padded_end[i][:lengths[i]]]\n",
    "            ) for i in range(len(sequences_padded_end))]\n",
    "        )\n",
    "\n",
    "        # don't forget to grab the labels of the *sorted* batch\n",
    "        labels = torch.LongTensor([x[1] for x in sorted_batch])\n",
    "        return sequences_padded_begin, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAD = HumanActionDataset(data_dir, data_files, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAD_masked = HumanActionDataset_Masked(data_dir, data_files, classes, 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 80% of the data for training and the remaining 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = torch.utils.data.random_split(HAD, [int(0.80*len(HAD)), len(HAD)-int(0.80*len(HAD))])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, collate_fn=PadSequence(), shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=32, collate_fn=PadSequence(), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_masked, val_dataset_masked = torch.utils.data.random_split(HAD_masked, [int(0.80*len(HAD_masked)), len(HAD_masked)-int(0.80*len(HAD_masked))])\n",
    "\n",
    "train_dataloader_masked = torch.utils.data.DataLoader(dataset=train_dataset_masked, batch_size=32, collate_fn=PadSequence(), shuffle=True)\n",
    "val_dataloader_masked = torch.utils.data.DataLoader(dataset=val_dataset_masked, batch_size=32, collate_fn=PadSequence(), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1.3 AUXILIARY FUNCTIONS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, nb_epochs, epoch_print_frequence, train_dataloader, val_dataloader):\n",
    "\n",
    "    s = time.time()\n",
    "\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "\n",
    "        running_loss_train, running_loss_val, running_acc_train, running_acc_val = 0, 0, 0, 0\n",
    "\n",
    "        for train in [True, False]:\n",
    "\n",
    "            if train:\n",
    "                dataloader = train_dataloader\n",
    "                model.train()\n",
    "            else:\n",
    "                dataloader = val_dataloader\n",
    "                model.eval()\n",
    "\n",
    "            for data in dataloader:\n",
    "                \n",
    "                inputs = data[0].to(device)\n",
    "                labels_raw = data[-1]\n",
    "                labels = torch.zeros((inputs.shape[0], len(classes)))\n",
    "                for i in range(len(labels_raw)):\n",
    "                    labels[i][int(labels_raw[i])] = 1\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                if train:\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                outputs_for_loss = model(inputs)\n",
    "                sm = nn.Softmax(dim=1).to(device)\n",
    "                outputs = sm(outputs_for_loss)\n",
    "                outputs = outputs.to(device)\n",
    "                loss = criterion(outputs_for_loss, labels)\n",
    "\n",
    "                if train:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss_train += loss.item()\n",
    "                    running_acc_train += int(torch.sum(outputs.argmax(dim=1) == labels.argmax(dim=1)))\n",
    "                else:\n",
    "                    running_loss_val += loss.item()\n",
    "                    running_acc_val += int(torch.sum(outputs.argmax(dim=1) == labels.argmax(dim=1)))\n",
    "\n",
    "        running_loss_train /= len(train_dataloader)\n",
    "        running_loss_val /= len(val_dataloader)\n",
    "        running_acc_train /= len(train_dataset)\n",
    "        running_acc_val /= len(val_dataset)\n",
    "\n",
    "        train_losses.append(running_loss_train)\n",
    "        val_losses.append(running_loss_val)\n",
    "        train_accs.append(running_acc_train)\n",
    "        val_accs.append(running_acc_val)\n",
    "\n",
    "        if (epoch+1) % epoch_print_frequence == 0:\n",
    "            print(\"epochs {} ({} s) | train loss : {} | val loss : {} | train acc : {} | val acc : {}\".format(\n",
    "                epoch+1,\n",
    "                int(time.time()-s),\n",
    "                int(1000000*running_loss_train)/1000000,\n",
    "                int(1000000*running_loss_val)/1000000,\n",
    "                int(1000000*running_acc_train)/1000000,\n",
    "                int(1000000*running_acc_val)/1000000\n",
    "            ))\n",
    "    \n",
    "    return train_losses, val_losses, train_accs, val_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. THE MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.1. Definition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM0(nn.Module):\n",
    "\n",
    "    def __init__(self, nb_classes, input_size, hidden_size_lstm, hidden_size_classifier, num_layers, device):\n",
    "\n",
    "        super(LSTM0, self).__init__()\n",
    "\n",
    "        self.num_classes = nb_classes   # number of classes\n",
    "        self.num_layers = num_layers    # number of layers\n",
    "        self.input_size = input_size    # input size\n",
    "        self.hidden_size = hidden_size_lstm  # hidden state\n",
    "        self.device = device\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size_lstm, num_layers=num_layers, batch_first=True) # lstm\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size_lstm, hidden_size_classifier),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size_classifier, nb_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device) # hidden state (short memory)\n",
    "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device) # internal state (long memory)\n",
    "        \n",
    "        _, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
    "        hn = hn.view(-1, self.hidden_size) # reshaping the data for clasifier\n",
    "        return self.classifier(hn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.2. Training*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *2.2.A On Full Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM0(\n",
       "  (lstm): LSTM(75, 256, batch_first=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=9, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSTM0 = LSTM0(nb_classes=len(classes), input_size=75, hidden_size_lstm=256, hidden_size_classifier=128, num_layers=1, device=device)\n",
    "model_LSTM0.to(device)\n",
    "model_LSTM0.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_LSTM0 = nn.CrossEntropyLoss()\n",
    "optimizer_LSTM0 = torch.optim.Adam(params=model_LSTM0.parameters(), lr=1e-4)\n",
    "lr_scheduler_LSTM0 = torch.optim.lr_scheduler.StepLR(optimizer_LSTM0, step_size=10, gamma=0.1)\n",
    "nb_epochs = 100\n",
    "epoch_print_frequence = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train and save this first model and see the evolution of the loss and accuracy over the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 25 (495 s) | train loss : 1.517722 | val loss : 1.533125 | train acc : 0.859066 | val acc : 0.838433\n",
      "epochs 50 (829 s) | train loss : 1.47841 | val loss : 1.48701 | train acc : 0.894414 | val acc : 0.884944\n",
      "epochs 75 (1100 s) | train loss : 1.463382 | val loss : 1.480473 | train acc : 0.908951 | val acc : 0.88678\n",
      "epochs 100 (1384 s) | train loss : 1.466856 | val loss : 1.473161 | train acc : 0.906197 | val acc : 0.903304\n"
     ]
    }
   ],
   "source": [
    "losses_accs_LSTM0 = train_model(model_LSTM0, criterion_LSTM0, optimizer_LSTM0, nb_epochs, epoch_print_frequence, train_dataloader, val_dataloader)\n",
    "torch.save(model_LSTM0.state_dict(), \"../models_saved/LSTM0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n",
    "\n",
    "ax[0].set(title=\"LSTM0 - Loss evolution\")\n",
    "ax[0].plot(losses_accs_LSTM0[0], label=\"train\")\n",
    "ax[0].plot(losses_accs_LSTM0[1], label=\"test\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"loss\")\n",
    "\n",
    "ax[1].set(title=\"LSTM0 - Accuracy evolution\")\n",
    "ax[1].plot(losses_accs_LSTM0[2], label=\"train\")\n",
    "ax[1].plot(losses_accs_LSTM0[3], label=\"test\")\n",
    "ax[1].set_xlabel(\"epoch\")\n",
    "ax[1].set_ylabel(\"accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the runs on 100 epochs:\n",
    "\n",
    "![LSTM0 loss and accuracy evolution](../models_saved/LSTM0_loss_acc.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the model is quite simple, the results are encouraging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better visualization, let's train the model multiple times and plot the average loss and accuracy evolutions.\n",
    "\n",
    "***Remark**: I stopped the process because my laptop strated to make a lot of noise.*\n",
    "\n",
    "***TODO**: I'll launch the next cells (along with grid search) in a PC from the school.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1/4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17556/501095201.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mepoch_print_frequence_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mlosses_accs_LSTM0_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_LSTM0_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion_LSTM0_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_LSTM0_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epochs_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_print_frequence_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mlosses_accs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses_accs_LSTM0_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17556/3760399286.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, nb_epochs, epoch_print_frequence)\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17556/495787197.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# (we had poor results with zeros at the end)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         sequences_padded_begin = torch.stack(\n\u001b[1;32m---> 18\u001b[1;33m             [torch.cat([\n\u001b[0m\u001b[0;32m     19\u001b[0m                 \u001b[0msequences_padded_end\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 sequences_padded_end[i][:lengths[i]]]\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17556/495787197.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m             [torch.cat([\n\u001b[0;32m     19\u001b[0m                 \u001b[0msequences_padded_end\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 sequences_padded_end[i][:lengths[i]]]\n\u001b[0m\u001b[0;32m     21\u001b[0m             ) for i in range(len(sequences_padded_end))]\n\u001b[0;32m     22\u001b[0m         )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses_accs = []\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    print(\"STEP {}/4\".format(i+1))\n",
    "\n",
    "    model_LSTM0_i = LSTM0(nb_classes=len(classes), input_size=75, hidden_size_lstm=256, hidden_size_classifier=128, num_layers=1, device=device)\n",
    "    model_LSTM0_i.to(device)\n",
    "    model_LSTM0_i.eval()\n",
    "\n",
    "    criterion_LSTM0_i = nn.CrossEntropyLoss()\n",
    "    optimizer_LSTM0_i = torch.optim.Adam(params=model_LSTM0_i.parameters(), lr=1e-4)\n",
    "    lr_scheduler_LSTM0_i = torch.optim.lr_scheduler.StepLR(optimizer_LSTM0_i, step_size=10, gamma=0.1)\n",
    "    nb_epochs_i = 100\n",
    "    epoch_print_frequence_i = 100\n",
    "\n",
    "    losses_accs_LSTM0_i = train_model(model_LSTM0_i, criterion_LSTM0_i, optimizer_LSTM0_i, nb_epochs_i, epoch_print_frequence_i, train_dataloader, val_dataloader)\n",
    "    losses_accs.append(losses_accs_LSTM0_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_accs_LSTM0_avg = []\n",
    "losses_accs_LSTM0_avg.append([sum([elem[0][i] for elem in losses_accs])/4 for i in range(len(losses_accs[0][0]))])\n",
    "losses_accs_LSTM0_avg.append([sum([elem[1][i] for elem in losses_accs])/4 for i in range(len(losses_accs[0][1]))])\n",
    "losses_accs_LSTM0_avg.append([sum([elem[2][i] for elem in losses_accs])/4 for i in range(len(losses_accs[0][2]))])\n",
    "losses_accs_LSTM0_avg.append([sum([elem[3][i] for elem in losses_accs])/4 for i in range(len(losses_accs[0][3]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n",
    "\n",
    "ax[0].set(title=\"LSTM0 - (Average) Loss evolution\")\n",
    "ax[0].plot(losses_accs_LSTM0_avg[0], label=\"train\")\n",
    "ax[0].plot(losses_accs_LSTM0_avg[1], label=\"test\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"loss\")\n",
    "\n",
    "ax[1].set(title=\"LSTM0 - (Average) Accuracy evolution\")\n",
    "ax[1].plot(losses_accs_LSTM0_avg[2], label=\"train\")\n",
    "ax[1].plot(losses_accs_LSTM0_avg[3], label=\"test\")\n",
    "ax[1].set_xlabel(\"epoch\")\n",
    "ax[1].set_ylabel(\"accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *2.2.B On Masked Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM0(\n",
       "  (lstm): LSTM(75, 256, batch_first=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=9, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSTM0_masked = LSTM0(nb_classes=len(classes), input_size=75, hidden_size_lstm=256, hidden_size_classifier=128, num_layers=1, device=device)\n",
    "model_LSTM0_masked.to(device)\n",
    "model_LSTM0_masked.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_LSTM0_masked = nn.CrossEntropyLoss()\n",
    "optimizer_LSTM0_masked = torch.optim.Adam(params=model_LSTM0_masked.parameters(), lr=1e-4)\n",
    "lr_scheduler_LSTM0_masked = torch.optim.lr_scheduler.StepLR(optimizer_LSTM0_masked, step_size=10, gamma=0.1)\n",
    "nb_epochs_masked = 80\n",
    "epoch_print_frequence_masked = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 10 (364 s) | train loss : 2.137563 | val loss : 2.13049 | train acc : 0.191736 | val acc : 0.197674\n",
      "epochs 20 (745 s) | train loss : 2.109805 | val loss : 2.098655 | train acc : 0.232134 | val acc : 0.231946\n",
      "epochs 30 (1125 s) | train loss : 2.092627 | val loss : 2.077346 | train acc : 0.254781 | val acc : 0.274173\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9192/37847564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlosses_accs_LSTM0_masked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_LSTM0_masked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion_LSTM0_masked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_LSTM0_masked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epochs_masked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_print_frequence_masked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader_masked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader_masked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_LSTM0_masked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"../models_saved/LSTM0_masked.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9192/842256854.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, nb_epochs, epoch_print_frequence, train_dataloader, val_dataloader)\u001b[0m\n\u001b[0;32m     36\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                     \u001b[0mrunning_loss_train\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m                     \u001b[0mrunning_acc_train\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses_accs_LSTM0_masked = train_model(model_LSTM0_masked, criterion_LSTM0_masked, optimizer_LSTM0_masked, nb_epochs_masked, epoch_print_frequence_masked, train_dataloader_masked, val_dataloader_masked)\n",
    "torch.save(model_LSTM0_masked.state_dict(), \"../models_saved/LSTM0_masked.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n",
    "\n",
    "ax[0].set(title=\"LSTM0 On Masked Data - Loss evolution\")\n",
    "ax[0].plot(losses_accs_LSTM0_masked[0], label=\"train\")\n",
    "ax[0].plot(losses_accs_LSTM0_masked[1], label=\"test\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"loss\")\n",
    "\n",
    "ax[1].set(title=\"LSTM0 On Masked Data - Accuracy evolution\")\n",
    "ax[1].plot(losses_accs_LSTM0_masked[2], label=\"train\")\n",
    "ax[1].plot(losses_accs_LSTM0_masked[3], label=\"test\")\n",
    "ax[1].set_xlabel(\"epoch\")\n",
    "ax[1].set_ylabel(\"accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Remark:** I stopped the learning because it's slow and doesn't seem to be efficient. I think we should find a first solid model (>95% accuracy) and then proceed with masked data.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.3. Grid Search*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find optimal parameters for this simple model among a relatively small set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes_lstm = [128, 256, 512]\n",
    "hidden_sizes_classifier = [64, 128, 256]\n",
    "num_layers = [1, 2]\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden_size_lstm in hidden_sizes_lstm:\n",
    "    for hidden_size_classifier in hidden_sizes_classifier:\n",
    "        for num_layer in num_layers:\n",
    "\n",
    "            print(\"hidden size lstm:       {}\".format(hidden_size_lstm))\n",
    "            print(\"hidden size classifier: {}\".format(hidden_size_classifier))\n",
    "            print(\"number of layers:       {}\".format(num_layer))\n",
    "\n",
    "            model_LSTM0_i = LSTM0(nb_classes=len(classes), input_size=75, hidden_size_lstm=hidden_size_lstm, hidden_size_classifier=hidden_size_classifier, num_layers=num_layer, device=device)\n",
    "            model_LSTM0_i.to(device)\n",
    "            model_LSTM0_i.eval()\n",
    "\n",
    "            criterion_LSTM0_i = nn.CrossEntropyLoss()\n",
    "            optimizer_LSTM0_i = torch.optim.Adam(params=model_LSTM0_i.parameters(), lr=1e-4)\n",
    "            lr_scheduler_LSTM0_i = torch.optim.lr_scheduler.StepLR(optimizer_LSTM0_i, step_size=10, gamma=0.1)\n",
    "            nb_epochs_i = 100\n",
    "            epoch_print_frequence_i = 100\n",
    "\n",
    "            results[(hidden_size_lstm, hidden_size_classifier, num_layer)] = train_model(model_LSTM0_i, criterion_LSTM0_i, optimizer_LSTM0_i, nb_epochs_i, epoch_print_frequence_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "118508df3531a4baef22a353ae7891686b2f0c3ff24a04c6bb67baeaff15e974"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
