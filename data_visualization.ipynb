{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of the NTU RGB+D Action Recognition Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Initialization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1.1. Imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "PIL                 8.4.0\n",
       "matplotlib          3.4.3\n",
       "numpy               1.21.3\n",
       "scipy               1.7.2\n",
       "session_info        1.0.0\n",
       "torch               1.10.0+cu102\n",
       "tqdm                4.62.3\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "astunparse                  1.6.3\n",
       "backcall                    0.2.0\n",
       "cffi                        1.15.0\n",
       "colorama                    0.4.4\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.4.3\n",
       "decorator                   5.1.0\n",
       "defusedxml                  0.7.1\n",
       "entrypoints                 0.3\n",
       "google                      NA\n",
       "ipykernel                   6.4.1\n",
       "ipython_genutils            0.2.0\n",
       "jedi                        0.18.0\n",
       "kiwisolver                  1.3.2\n",
       "matplotlib_inline           NA\n",
       "mpl_toolkits                NA\n",
       "nt                          NA\n",
       "ntsecuritycon               NA\n",
       "pandas                      1.3.4\n",
       "parso                       0.8.2\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "prompt_toolkit              3.0.20\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.4.1\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pyexpat                     NA\n",
       "pygments                    2.10.0\n",
       "pyparsing                   3.0.6\n",
       "pythoncom                   NA\n",
       "pytz                        2021.3\n",
       "pywin32_bootstrap           NA\n",
       "pywin32_system32            NA\n",
       "pywintypes                  NA\n",
       "six                         1.16.0\n",
       "storemagic                  NA\n",
       "tornado                     6.1\n",
       "traitlets                   5.1.0\n",
       "typing_extensions           NA\n",
       "wcwidth                     0.2.5\n",
       "win32api                    NA\n",
       "win32com                    NA\n",
       "win32security               NA\n",
       "zmq                         22.3.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             7.29.0\n",
       "jupyter_client      7.0.2\n",
       "jupyter_core        4.7.1\n",
       "notebook            6.4.3\n",
       "-----\n",
       "Python 3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]\n",
       "Windows-10-10.0.22000-SP0\n",
       "-----\n",
       "Session information updated at 2022-02-01 15:00\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fill the requirement.txt file we use the following line of code:\n",
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1.2. Data Loading*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2D_dir = \"data/nturgbd60_skeletons_2D/\"\n",
    "data3D_dir = \"data/nturgbd60_skeletons_3D/\"\n",
    "\n",
    "data2D_files = os.listdir(data2D_dir)\n",
    "data3D_files = os.listdir(data3D_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/actions.txt\", 'r') as actions_file:\n",
    "    actions = [line.replace('\\n', '') for line in actions_file.readlines()]\n",
    "    actions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 : pickup\n",
      "class 1 : throw\n",
      "class 2 : sitting down\n",
      "class 3 : standing up (from sitting position)\n",
      "class 4 : take off jacket\n",
      "class 5 : reach into pocket\n",
      "class 6 : pointing to something with finger\n",
      "class 7 : check time (from watch)\n",
      "class 8 : falling\n"
     ]
    }
   ],
   "source": [
    "classes = [5, 6, 7, 8, 14, 24, 30, 32, 42]\n",
    "for i,elem in enumerate(classes):\n",
    "    print(\"class {} : {}\".format(i, actions[elem]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanActionDataset2D(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, data_files, classes, with_depth=True, flatten=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_files = [data_file for data_file in data_files if int(data_file[17:-4])-1 in classes]\n",
    "        self.classes = classes\n",
    "        self.with_depth = with_depth\n",
    "        self.flatten =  flatten\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor = torch.Tensor(np.load(self.data_dir + self.data_files[idx]))\n",
    "        if not self.with_depth:\n",
    "            tensor = tensor[:,:,:2]\n",
    "        if self.flatten:\n",
    "            tensor = tensor.reshape((tensor.shape[0], tensor.shape[1]*tensor.shape[2]))\n",
    "        label = self.classes.index(int(self.data_files[idx][17:-4])-1)\n",
    "        return (tensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanActionDataset3D(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, data_files, classes, flatten=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_files = [data_file for data_file in data_files if int(data_file[17:-4])-1 in classes]\n",
    "        self.classes = classes\n",
    "        self.flatten =  flatten\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor = torch.Tensor(np.load(self.data_dir + self.data_files[idx]))\n",
    "        if self.flatten:\n",
    "            tensor = tensor.reshape((tensor.shape[0], tensor.shape[1]*tensor.shape[2]))\n",
    "        label = self.classes.index(int(self.data_files[idx][17:-4])-1)\n",
    "        return (tensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAD2D = HumanActionDataset2D(data2D_dir, data2D_files, classes, with_depth=False, flatten=False)\n",
    "HAD3D = HumanActionDataset3D(data3D_dir, data3D_files, classes, flatten=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Create Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences of joints to display the members of the squeletons\n",
    "\n",
    "bust_joints = [0, 1, 20, 2, 3]\n",
    "\n",
    "right_arm_joint = [23, 24, 11, 10, 9, 8]\n",
    "left_arm_joint = [21, 22, 7, 6, 5, 4]\n",
    "arm_joints = [23, 24, 11, 10, 9, 8, 20, 4, 5, 6, 7, 22, 21]\n",
    "\n",
    "right_leg_joints = []\n",
    "left_leg_joints = []\n",
    "leg_joints = [19, 18, 17, 16, 0, 12, 13, 14, 15]\n",
    "\n",
    "body_joints = [bust_joints, arm_joints, leg_joints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_sequence(i, dataset2D=HAD2D, dataset3D=HAD3D):\n",
    "    \n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    * (int) i : index of the sample to consider\n",
    "    * dataset2D : dataset with the pixel information\n",
    "    * dataset3D : dataset with the space information (if not None we will consider the depth in the generated images)\n",
    "\n",
    "    output:\n",
    "    * final_image_sequence : sequence (frame by frame) of images + depth\n",
    "    \"\"\"\n",
    "    \n",
    "    xy_sequence = dataset2D[i][0]\n",
    "    image_sequence = np.zeros((xy_sequence.shape[0],25,3))\n",
    "    \n",
    "    if dataset3D != None:\n",
    "        z_sequence = dataset3D[i][0][:,:,2]\n",
    "    else:\n",
    "        z_sequence = np.zeros((xy_sequence.shape[0],25))\n",
    "    \n",
    "    for m in range(xy_sequence.shape[0]):\n",
    "        for n in range(25):\n",
    "            x = min(int(xy_sequence[m,n,0].item()),1920)-1\n",
    "            y = min(int(xy_sequence[m,n,1].item()),1080)-1\n",
    "            z = z_sequence[m,n].item()\n",
    "            image_sequence[m,n] = [x,y,z]\n",
    "    \n",
    "    return  image_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_sequence_normalize(i, dataset2D=HAD2D, dataset3D=HAD3D):\n",
    "    # get pixels but also normalize the depth between 0 and 1\n",
    "    image_sequence = get_image_sequence(i, dataset2D, dataset3D)\n",
    "    mini = image_sequence[:,:,2].min()\n",
    "    maxi = image_sequence[:,:,2].max()\n",
    "    if mini != maxi:\n",
    "        image_sequence[:,:,2] = (image_sequence[:,:,2]-mini)/(maxi-mini)\n",
    "    return image_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(image_frame):\n",
    "\n",
    "    img = Image.new(\"RGB\", (1920,1080 ), color=\"black\")\n",
    "    \n",
    "    for body_part in body_joints:\n",
    "        \n",
    "        for i in range(len(body_part)-1):\n",
    "            \n",
    "            a = image_frame[body_part[i]]\n",
    "            b = image_frame[body_part[i+1]]-a\n",
    "            n = 10\n",
    "            line = np.array([a+(i/n)*b for i in range(n)])\n",
    "\n",
    "            for i in range(len(line)-1):\n",
    "                x1,y1,z = line[i]\n",
    "                x2,y2,_ = line[i+1]\n",
    "                draw = ImageDraw.Draw(img)\n",
    "                color = tuple((int(255*z),0,int(255*(1-z))))\n",
    "                draw.line((x1,y1,x2,y2), fill=color,width=5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1920x1080 at 0x22F7FC54E80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example (first element of the dataset)\n",
    "create_image(get_image_sequence_normalize(15)[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif(i, filepath, dataset2D=HAD2D, dataset3D=HAD3D, normalize=True):\n",
    "    if normalize:\n",
    "        image_sequence = get_image_sequence_normalize(i, dataset2D, dataset3D)\n",
    "    else:\n",
    "        image_sequence = get_image_sequence(i, dataset2D, dataset3D)\n",
    "    seq = [create_image(frame) for frame in image_sequence]\n",
    "    seq[0].save(filepath, save_all=True, append_images=seq[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"gifs\" not in os.listdir(\"./data/\"):\n",
    "    os.mkdir(\"./data/gifs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(100):\n",
    "    create_gif(index, \"./data/gifs/sample_{}_A{}.gif\".format(index, classes[HAD2D[index][1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "118508df3531a4baef22a353ae7891686b2f0c3ff24a04c6bb67baeaff15e974"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
